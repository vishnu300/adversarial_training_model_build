{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe9df13",
   "metadata": {},
   "source": [
    "# To use colab python3 GPU that will more fast than local cpu\n",
    "# !/usr/bin/env python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f8ea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/you/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent, DeepFool\n",
    "from art.estimators.classification import PyTorchClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c90b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "def load_cifar10_data(batch_size=128, num_samples=1000):\n",
    "    print(\"Loading CIFAR10 dataset...\")\n",
    "\n",
    "    # CIFAR10 normalization values\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "    # Load training and test datasets\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    # Use a subset for faster evaluation\n",
    "    if num_samples < len(test_dataset):\n",
    "        indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
    "        test_dataset = Subset(test_dataset, indices)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Class names\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "    return train_loader, test_loader, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b08ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(num_classes=10):\n",
    "\n",
    "    print(\"Loading pre-trained ResNet-18 model...\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = torchvision.models.resnet18(pretrained=True) # Load pre-trained ResNet18 and modify for CIFAR10\n",
    "\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False) # conv layer for CIFAR10 (32x32 images)\n",
    "    model.maxpool = nn.Identity()  # Remove max pooling\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)  # Modify final layer for CIFAR10 (10 classes)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690b2fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71d9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_art_classifier(model, device):\n",
    "    criterion = nn.CrossEntropyLoss()     # Define loss function and optimizer (not used for inference but required by ART)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=criterion,\n",
    "        optimizer=optimizer,\n",
    "        input_shape=(3, 32, 32),\n",
    "        nb_classes=10,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        device_type='gpu' if device.type == 'cuda' else 'cpu'\n",
    "    )\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563e8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_art_classifier(model, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=criterion,\n",
    "        optimizer=optimizer,\n",
    "        input_shape=(3, 32, 32),\n",
    "        nb_classes=10,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        device_type='gpu' if device.type == 'cuda' else 'cpu'\n",
    "    )\n",
    "\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def generate_adversarial_examples(classifier, attack_name, x_test, y_test, epsilon=0.03):\n",
    "    print(f\"\\nGenerating adversarial examples using {attack_name.upper()}...\")\n",
    "    print(f\"Epsilon: {epsilon}\")\n",
    "\n",
    "    if attack_name.lower() == 'fgsm':\n",
    "        attack = FastGradientMethod(estimator=classifier, eps=epsilon)\n",
    "    elif attack_name.lower() == 'pgd':\n",
    "        attack = ProjectedGradientDescent(\n",
    "            estimator=classifier,\n",
    "            eps=epsilon,\n",
    "            eps_step=epsilon/10,\n",
    "            max_iter=40,\n",
    "            targeted=False\n",
    "        )\n",
    "    elif attack_name.lower() == 'deepfool':\n",
    "        attack = DeepFool(classifier=classifier, max_iter=50, epsilon=1e-6)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown attack: {attack_name}\")\n",
    "\n",
    "    # Generate adversarial examples\n",
    "    x_adv = attack.generate(x=x_test)\n",
    "\n",
    "    return x_adv, attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_adversarial_robustness(classifier, x_test, y_test, attack_configs):\n",
    "    print(\"\\nEvaluating on clean data...\")\n",
    "    clean_preds = classifier.predict(x_test)\n",
    "    clean_accuracy = np.mean(np.argmax(clean_preds, axis=1) == np.argmax(y_test, axis=1)) * 100\n",
    "    print(f\"Clean Accuracy: {clean_accuracy:.2f}%\")\n",
    "\n",
    "    results = {\n",
    "        'clean': {\n",
    "            'accuracy': clean_accuracy,\n",
    "            'predictions': clean_preds\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for attack_config in attack_configs:\n",
    "        attack_name = attack_config['name']\n",
    "        epsilon = attack_config.get('epsilon', 0.03)\n",
    "\n",
    "        try:\n",
    "            x_adv, attack = generate_adversarial_examples(\n",
    "                classifier, attack_name, x_test, y_test, epsilon\n",
    "            )\n",
    "\n",
    "            print(f\"Evaluating on {attack_name.upper()} adversarial examples...\")\n",
    "            adv_preds = classifier.predict(x_adv)\n",
    "            adv_accuracy = np.mean(np.argmax(adv_preds, axis=1) == np.argmax(y_test, axis=1)) * 100\n",
    "            print(f\"{attack_name.upper()} Adversarial Accuracy: {adv_accuracy:.2f}%\")\n",
    "\n",
    "            perturbation = np.abs(x_adv - x_test)\n",
    "            avg_perturbation = np.mean(perturbation)\n",
    "            max_perturbation = np.max(perturbation)\n",
    "\n",
    "            results[attack_name] = {\n",
    "                'accuracy': adv_accuracy,\n",
    "                'predictions': adv_preds,\n",
    "                'adversarial_examples': x_adv,\n",
    "                'avg_perturbation': avg_perturbation,\n",
    "                'max_perturbation': max_perturbation,\n",
    "                'epsilon': epsilon\n",
    "            }\n",
    "\n",
    "            print(f\"Average perturbation: {avg_perturbation:.6f}\")\n",
    "            print(f\"Max perturbation: {max_perturbation:.6f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nWarning: {attack_name.upper()} attack failed: {str(e)}\")\n",
    "            print(f\"Skipping {attack_name.upper()} attack and continuing with others...\")\n",
    "            continue\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def visualize_accuracy_comparison(results, output_path='results/accuracy_comparison.png'):\n",
    "    print(\"\\nCreating accuracy comparison plot...\")\n",
    "    attack_names = list(results.keys())\n",
    "    accuracies = [results[name]['accuracy'] for name in attack_names]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(range(len(attack_names)), accuracies, color=['green', 'red', 'orange', 'purple'][:len(attack_names)])\n",
    "\n",
    "    plt.xlabel('Attack Type', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    plt.title('Model Accuracy: Clean vs Adversarial Examples', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(attack_names)), [name.upper() for name in attack_names])\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved accuracy comparison to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def visualize_adversarial_examples(x_clean, x_adv_dict, y_true, classes,\n",
    "                                   num_samples=5, output_path='results/adversarial_examples.png'):\n",
    "    print(\"\\nCreating adversarial examples visualization...\")\n",
    "\n",
    "    # Denormalize for visualization\n",
    "    mean = np.array([0.4914, 0.4822, 0.4465]).reshape(1, 3, 1, 1)\n",
    "    std = np.array([0.2023, 0.1994, 0.2010]).reshape(1, 3, 1, 1)\n",
    "\n",
    "    def denormalize(x):\n",
    "        x_denorm = x * std + mean\n",
    "        return np.clip(x_denorm, 0, 1)\n",
    "\n",
    "    # Select random samples\n",
    "    indices = np.random.choice(len(x_clean), num_samples, replace=False)\n",
    "\n",
    "    # Get attack names (excluding 'clean')\n",
    "    attack_names = [name for name in x_adv_dict.keys() if name != 'clean']\n",
    "\n",
    "    # Create subplots\n",
    "    num_cols = len(attack_names) + 1  # +1 for original\n",
    "    fig, axes = plt.subplots(num_samples, num_cols, figsize=(4*num_cols, 4*num_samples))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        # Original image\n",
    "        img_clean = denormalize(x_clean[idx:idx+1])[0].transpose(1, 2, 0)\n",
    "        true_label = np.argmax(y_true[idx])\n",
    "\n",
    "        axes[i, 0].imshow(img_clean)\n",
    "        axes[i, 0].set_title(f'Original\\nTrue: {classes[true_label]}', fontsize=10, fontweight='bold')\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Adversarial images\n",
    "        for j, attack_name in enumerate(attack_names):\n",
    "            x_adv = x_adv_dict[attack_name]\n",
    "            img_adv = denormalize(x_adv[idx:idx+1])[0].transpose(1, 2, 0)\n",
    "\n",
    "            # Calculate perturbation\n",
    "            perturbation = np.abs(img_adv - img_clean)\n",
    "            avg_pert = np.mean(perturbation)\n",
    "\n",
    "            axes[i, j+1].imshow(img_adv)\n",
    "            axes[i, j+1].set_title(f'{attack_name.upper()}\\nPert: {avg_pert:.4f}',\n",
    "                                   fontsize=10, fontweight='bold')\n",
    "            axes[i, j+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved adversarial examples to {output_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5269be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_perturbations(x_clean, x_adv_dict, num_samples=5, output_path='results/perturbation_magnitudes.png'):\n",
    "\n",
    "    print(\"\\nCreating perturbation visualization...\")\n",
    "\n",
    "    indices = np.random.choice(len(x_clean), num_samples, replace=False)\n",
    "\n",
    "    attack_names = [name for name in x_adv_dict.keys() if name != 'clean']\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, len(attack_names), figsize=(4*len(attack_names), 4*num_samples))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    if len(attack_names) == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        for j, attack_name in enumerate(attack_names):\n",
    "            x_adv = x_adv_dict[attack_name]\n",
    "\n",
    "            perturbation = np.abs(x_adv[idx] - x_clean[idx])\n",
    "            perturbation = perturbation.transpose(1, 2, 0)\n",
    "            perturbation = np.mean(perturbation, axis=2)  # Average across channels\n",
    "\n",
    "            im = axes[i, j].imshow(perturbation, cmap='hot')\n",
    "            axes[i, j].set_title(f'{attack_name.upper()}\\nMax: {np.max(perturbation):.4f}',\n",
    "                               fontsize=10, fontweight='bold')\n",
    "            axes[i, j].axis('off')\n",
    "            plt.colorbar(im, ax=axes[i, j], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved perturbation magnitudes to {output_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14b9cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_report(results, output_path='results/analysis_report.txt'):\n",
    "\n",
    "    print(\"\\nGenerating analysis report...\")\n",
    "\n",
    "    report = []\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"ADVERSARIAL ROBUSTNESS EVALUATION REPORT\")\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"\")\n",
    "\n",
    "    # Clean accuracy\n",
    "    clean_acc = results['clean']['accuracy']\n",
    "    report.append(f\"Clean Data Accuracy: {clean_acc:.2f}%\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    # Attack results\n",
    "    report.append(\"Adversarial Attack Results:\")\n",
    "    report.append(\"-\" * 80)\n",
    "\n",
    "    for attack_name, data in results.items():\n",
    "        if attack_name == 'clean':\n",
    "            continue\n",
    "\n",
    "        acc = data['accuracy']\n",
    "        epsilon = data.get('epsilon', 'N/A')\n",
    "        avg_pert = data.get('avg_perturbation', 0)\n",
    "        max_pert = data.get('max_perturbation', 0)\n",
    "\n",
    "        accuracy_drop = clean_acc - acc\n",
    "\n",
    "        report.append(f\"\\n{attack_name.upper()} Attack:\")\n",
    "        report.append(f\"  - Epsilon: {epsilon}\")\n",
    "        report.append(f\"  - Adversarial Accuracy: {acc:.2f}%\")\n",
    "        report.append(f\"  - Accuracy Drop: {accuracy_drop:.2f}%\")\n",
    "        report.append(f\"  - Average Perturbation: {avg_pert:.6f}\")\n",
    "        report.append(f\"  - Max Perturbation: {max_pert:.6f}\")\n",
    "\n",
    "    report.append(\"\")\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"ANALYSIS AND INSIGHTS\")\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"\")\n",
    "\n",
    "    # Analysis\n",
    "    report.append(\"1. ATTACK EFFECTIVENESS:\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    # Find most and least effective attacks\n",
    "    attack_accs = {name: data['accuracy'] for name, data in results.items() if name != 'clean'}\n",
    "    most_effective = min(attack_accs, key=attack_accs.get)\n",
    "    least_effective = max(attack_accs, key=attack_accs.get)\n",
    "\n",
    "    report.append(f\"   - Most effective attack: {most_effective.upper()} \"\n",
    "                 f\"(accuracy dropped to {attack_accs[most_effective]:.2f}%)\")\n",
    "    report.append(f\"   - Least effective attack: {least_effective.upper()} \"\n",
    "                 f\"(accuracy dropped to {attack_accs[least_effective]:.2f}%)\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    report.append(\"2. CONCEPTUAL DIFFERENCES BETWEEN ATTACKS:\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"   FGSM (Fast Gradient Sign Method):\")\n",
    "    report.append(\"   - Single-step attack using the sign of the gradient\")\n",
    "    report.append(\"   - Fast to compute but less sophisticated\")\n",
    "    report.append(\"   - Perturbation: x_adv = x + ε * sign(∇_x L(θ, x, y))\")\n",
    "    report.append(\"   - Pros: Very fast, good for adversarial training\")\n",
    "    report.append(\"   - Cons: Less effective than iterative methods\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    report.append(\"   PGD (Projected Gradient Descent):\")\n",
    "    report.append(\"   - Iterative attack with multiple small steps\")\n",
    "    report.append(\"   - Projects perturbation back to epsilon ball after each step\")\n",
    "    report.append(\"   - Considered one of the strongest first-order attacks\")\n",
    "    report.append(\"   - Pros: More effective, better explores adversarial space\")\n",
    "    report.append(\"   - Cons: Computationally expensive (multiple iterations)\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    if 'deepfool' in results:\n",
    "        report.append(\"   DeepFool:\")\n",
    "        report.append(\"   - Finds minimal perturbation to cross decision boundary\")\n",
    "        report.append(\"   - Uses geometric approach to find optimal direction\")\n",
    "        report.append(\"   - Iteratively linearizes the classifier\")\n",
    "        report.append(\"   - Pros: Minimal perturbations, geometrically meaningful\")\n",
    "        report.append(\"   - Cons: More complex, computationally intensive\")\n",
    "        report.append(\"\")\n",
    "\n",
    "    report.append(\"3. OBSERVED VULNERABILITIES:\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    # Calculate average accuracy drop\n",
    "    avg_drop = np.mean([clean_acc - data['accuracy'] for name, data in results.items() if name != 'clean'])\n",
    "\n",
    "    if avg_drop > 40:\n",
    "        report.append(f\"   - The model shows SIGNIFICANT vulnerability to adversarial attacks\")\n",
    "        report.append(f\"   - Average accuracy drop: {avg_drop:.2f}%\")\n",
    "        report.append(\"   - This indicates the model relies heavily on non-robust features\")\n",
    "    elif avg_drop > 20:\n",
    "        report.append(f\"   - The model shows MODERATE vulnerability to adversarial attacks\")\n",
    "        report.append(f\"   - Average accuracy drop: {avg_drop:.2f}%\")\n",
    "        report.append(\"   - There is substantial room for robustness improvement\")\n",
    "    else:\n",
    "        report.append(f\"   - The model shows RELATIVELY LOW vulnerability to adversarial attacks\")\n",
    "        report.append(f\"   - Average accuracy drop: {avg_drop:.2f}%\")\n",
    "        report.append(\"   - The model exhibits some inherent robustness\")\n",
    "\n",
    "    report.append(\"\")\n",
    "    report.append(\"4. MITIGATION STRATEGIES:\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"   Recommended approaches to improve adversarial robustness:\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"   a) Adversarial Training:\")\n",
    "    report.append(\"      - Train on mix of clean and adversarial examples\")\n",
    "    report.append(\"      - Use PGD-generated adversarial examples during training\")\n",
    "    report.append(\"      - Most effective defense but computationally expensive\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"   b) Input Preprocessing:\")\n",
    "    report.append(\"      - Apply transformations (JPEG compression, bit-depth reduction)\")\n",
    "    report.append(\"      - Use denoising autoencoders\")\n",
    "    report.append(\"      - Random resizing and padding\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"   c) Certified Defenses:\")\n",
    "    report.append(\"      - Randomized smoothing\")\n",
    "    report.append(\"      - Provable robustness guarantees within epsilon ball\")\n",
    "    report.append(\"      - Trade-off between robustness and accuracy\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"   d) Ensemble Methods:\")\n",
    "    report.append(\"      - Use multiple models with different architectures\")\n",
    "    report.append(\"      - Adversarial examples may not transfer well\")\n",
    "    report.append(\"      - Increases computational cost\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"   e) Detection Methods:\")\n",
    "    report.append(\"      - Train adversarial example detectors\")\n",
    "    report.append(\"      - Reject suspicious inputs\")\n",
    "    report.append(\"      - Can be bypassed by adaptive attacks\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    report.append(\"5. RECOMMENDATIONS:\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"   Based on the evaluation results:\")\n",
    "    report.append(f\"   - Priority: Implement adversarial training with PGD (ε={results.get('pgd', {}).get('epsilon', 0.03)})\")\n",
    "    report.append(\"   - Consider: Input preprocessing as additional defense layer\")\n",
    "    report.append(\"   - Evaluate: Trade-off between clean and robust accuracy\")\n",
    "    report.append(\"   - Monitor: Model performance on diverse adversarial attacks\")\n",
    "    report.append(\"\")\n",
    "\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"END OF REPORT\")\n",
    "    report.append(\"=\" * 80)\n",
    "\n",
    "    # Save report\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('\\n'.join(report))\n",
    "\n",
    "    print(f\"Saved analysis report to {output_path}\")\n",
    "\n",
    "    # Also print to console\n",
    "    print(\"\\n\" + \"\\n\".join(report))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f89df3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ADVERSARIAL ROBUSTNESS EVALUATION PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    NUM_TEST_SAMPLES = 1000  # Use subset for faster evaluation\n",
    "    BATCH_SIZE = 128\n",
    "    EPSILON = 0.03  # Perturbation magnitude\n",
    "\n",
    "    train_loader, test_loader, classes = load_cifar10_data( batch_size=BATCH_SIZE,num_samples=NUM_TEST_SAMPLES)\n",
    "\n",
    "    # Step 2: Load pre-trained model\n",
    "    model, device = load_pretrained_model(num_classes=10)\n",
    "\n",
    "    # Step 3: Evaluate clean accuracy\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EVALUATING CLEAN ACCURACY\")\n",
    "    print(\"=\"*80)\n",
    "    clean_accuracy = evaluate_model(model, test_loader, device)\n",
    "    print(f\"\\nClean Test Accuracy: {clean_accuracy:.2f}%\")\n",
    "\n",
    "    # Step 4: Prepare data for ART\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREPARING DATA FOR ADVERSARIAL ATTACKS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Get test data as numpy arrays\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        x_test_list.append(images.numpy())\n",
    "        y_test_list.append(labels.numpy())\n",
    "\n",
    "    x_test = np.concatenate(x_test_list, axis=0)\n",
    "    y_test_labels = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_test = np.eye(10)[y_test_labels]\n",
    "\n",
    "    print(f\"Test data shape: {x_test.shape}\")\n",
    "    print(f\"Test labels shape: {y_test.shape}\")\n",
    "\n",
    "    # Step 5: Create ART classifier\n",
    "    classifier = create_art_classifier(model, device)\n",
    "\n",
    "    # Step 6: Generate and evaluate adversarial examples\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING AND EVALUATING ADVERSARIAL EXAMPLES\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    attack_configs = [\n",
    "        {'name': 'fgsm', 'epsilon': EPSILON},\n",
    "        {'name': 'pgd', 'epsilon': EPSILON},]\n",
    "\n",
    "    results = evaluate_adversarial_robustness(classifier, x_test, y_test, attack_configs)\n",
    "\n",
    "    # Step 7: Create visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CREATING VISUALIZATIONS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Accuracy comparison\n",
    "    visualize_accuracy_comparison(results)\n",
    "\n",
    "    # Adversarial examples\n",
    "    x_adv_dict = {name: data.get('adversarial_examples', x_test)\n",
    "                  for name, data in results.items()}\n",
    "    visualize_adversarial_examples(x_test, x_adv_dict, y_test, classes)\n",
    "\n",
    "    # Perturbation magnitudes\n",
    "    visualize_perturbations(x_test, x_adv_dict)\n",
    "\n",
    "    # Step 8: Generate analysis report\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING ANALYSIS REPORT\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    generate_analysis_report(results)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nResults saved in 'results/' directory:\")\n",
    "    print(\"  - accuracy_comparison.png\")\n",
    "    print(\"  - adversarial_examples.png\")\n",
    "    print(\"  - perturbation_magnitudes.png\")\n",
    "    print(\"  - analysis_report.txt\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ADVERSARIAL ROBUSTNESS EVALUATION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Loading CIFAR10 dataset...\n",
      "Training samples: 50000\n",
      "Test samples: 1000\n",
      "Loading pre-trained ResNet-18 model...\n",
      "Using device: cpu\n",
      "\n",
      "================================================================================\n",
      "EVALUATING CLEAN ACCURACY\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:05<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean Test Accuracy: 10.10%\n",
      "\n",
      "================================================================================\n",
      "PREPARING DATA FOR ADVERSARIAL ATTACKS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (1000, 3, 32, 32)\n",
      "Test labels shape: (1000, 10)\n",
      "\n",
      "================================================================================\n",
      "GENERATING AND EVALUATING ADVERSARIAL EXAMPLES\n",
      "================================================================================\n",
      "\n",
      "Evaluating on clean data...\n",
      "Clean Accuracy: 10.10%\n",
      "\n",
      "Generating adversarial examples using FGSM...\n",
      "Epsilon: 0.03\n",
      "Evaluating on FGSM adversarial examples...\n",
      "FGSM Adversarial Accuracy: 9.60%\n",
      "Average perturbation: 0.029771\n",
      "Max perturbation: 0.030000\n",
      "\n",
      "Generating adversarial examples using PGD...\n",
      "Epsilon: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m     54\u001b[39m attack_configs = [\n\u001b[32m     55\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mfgsm\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mepsilon\u001b[39m\u001b[33m'\u001b[39m: EPSILON},\n\u001b[32m     56\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mpgd\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mepsilon\u001b[39m\u001b[33m'\u001b[39m: EPSILON},]\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m results = \u001b[43mevaluate_adversarial_robustness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_configs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Step 7: Create visualizations\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mevaluate_adversarial_robustness\u001b[39m\u001b[34m(classifier, x_test, y_test, attack_configs)\u001b[39m\n\u001b[32m     16\u001b[39m epsilon = attack_config.get(\u001b[33m'\u001b[39m\u001b[33mepsilon\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0.03\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     x_adv, attack = \u001b[43mgenerate_adversarial_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvaluating on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattack_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m adversarial examples...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m     adv_preds = classifier.predict(x_adv)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mgenerate_adversarial_examples\u001b[39m\u001b[34m(classifier, attack_name, x_test, y_test, epsilon)\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown attack: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattack_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Generate adversarial examples\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m x_adv = \u001b[43mattack\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x_adv, attack\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent.py:202\u001b[39m, in \u001b[36mProjectedGradientDescent.generate\u001b[39m\u001b[34m(self, x, y, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03mGenerate adversarial samples and return them in an array.\u001b[39;00m\n\u001b[32m    189\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    199\u001b[39m \u001b[33;03m:return: An array holding the adversarial examples.\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    201\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mCreating adversarial samples.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_attack\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py:223\u001b[39m, in \u001b[36mProjectedGradientDescentPyTorch.generate\u001b[39m\u001b[34m(self, x, y, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rand_init_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_random_init)):\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m rand_init_num == \u001b[32m0\u001b[39m:\n\u001b[32m    222\u001b[39m         \u001b[38;5;66;03m# first iteration: use the adversarial examples as they are the only ones we have now\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m         adv_x[batch_index_1:batch_index_2] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_eps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_eps_step\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    227\u001b[39m         adversarial_batch = \u001b[38;5;28mself\u001b[39m._generate_batch(\n\u001b[32m    228\u001b[39m             x=batch, targets=batch_labels, mask=mask_batch, eps=batch_eps, eps_step=batch_eps_step\n\u001b[32m    229\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py:284\u001b[39m, in \u001b[36mProjectedGradientDescentPyTorch._generate_batch\u001b[39m\u001b[34m(self, x, targets, mask, eps, eps_step)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i_max_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_iter):\n\u001b[32m    283\u001b[39m     \u001b[38;5;28mself\u001b[39m._i_max_iter = i_max_iter\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     adv_x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_pytorch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43madv_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_random_init\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi_max_iter\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m adv_x.cpu().detach().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py:445\u001b[39m, in \u001b[36mProjectedGradientDescentPyTorch._compute_pytorch\u001b[39m\u001b[34m(self, x, x_init, y, mask, eps, eps_step, random_init, momentum)\u001b[39m\n\u001b[32m    442\u001b[39m     x_adv = x\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Get perturbation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m perturbation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_perturbation_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_adv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# Apply perturbation and clip\u001b[39;00m\n\u001b[32m    448\u001b[39m x_adv = \u001b[38;5;28mself\u001b[39m._apply_perturbation_pytorch(x_adv, perturbation, eps_step)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py:309\u001b[39m, in \u001b[36mProjectedGradientDescentPyTorch._compute_perturbation_pytorch\u001b[39m\u001b[34m(self, x, y, mask, momentum)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Get gradient wrt loss; invert it if attack is targeted\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m grad = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m * (-\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.targeted \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m)\n\u001b[32m    311\u001b[39m \u001b[38;5;66;03m# Write summary\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.summary_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/art/estimators/classification/pytorch.py:856\u001b[39m, in \u001b[36mPyTorchClassifier.loss_gradient\u001b[39m\u001b[34m(self, x, y, training_mode, **kwargs)\u001b[39m\n\u001b[32m    853\u001b[39m         scaled_loss.backward()\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    858\u001b[39m grads: torch.Tensor | np.ndarray\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x_grad.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/files/appointment_system/claud-appoimnet/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c71f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171e536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd0630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
